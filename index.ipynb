{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Recommendation System in PySpark - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this last lab, we will implement a a movie recommendation system using ALS in Spark programming environment. Spark's machine learning libraray `ml` comes packaged with a very efficient imeplementation of ALS algorithm that we looked at in the previous lesson. The lab will require you to put into pratice your spark programming skills for creating and manipulating pyspark DataFrames. We will go through a step-by-step process into developing a movie recommendation system using ALS and pyspark using the MovieLens Dataset that we used in a previous lab.\n",
    "\n",
    "Note: You are advised to refer to [PySpark Documentation](http://spark.apache.org/docs/2.2.0/api/python/index.html) heavily for completing this lab as it will introduce a few new methods. \n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Demonstrate an understanding on how recommendation systems are being used for personalization of online services/products\n",
    "* Parse and filter datasets into Spark RDDs, performing basic feature selection\n",
    "* Run a brief hyper-parameter selection activity through a scalable grid search\n",
    "* Train and evaluate the predictive performance of recommendation system\n",
    "* Generate predictions from the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Recommendation System\n",
    "\n",
    "We have seen how recommender/Recommendation Systems have played an  integral parts in the success of Amazon (Books, Items), Pandora/Spotify (Music), Google (News, Search), YouTube (Videos) etc.  For Amazon these systems bring more than 30% of their total revenues. For Netflix service, 75% of movies that people watch are based on some sort of recommendation.\n",
    "\n",
    "> The goal of Recommendation Systems is to find what is likely to be of interest to the user. This enables organizations to offer a high level of personalization and customer tailored services.\n",
    "\n",
    "\n",
    "For online video content services like Netflix and Hulu, the need to build robust movie recommendation systems is extremely important. An example of recommendation system is such as this:\n",
    "\n",
    "1.    User A watches Game of Thrones and Breaking Bad.\n",
    "2.    User B performs a search query for Game of Thrones.\n",
    "3.    The system suggests Breaking Bad to user B from data collected about user A.\n",
    "\n",
    "\n",
    "This lab will guide you through a step-by-step process into developing such a movie recommendation system. We will use the MovieLens dataset to build a movie recommendation system using the collaborative filtering technique with Spark's Alternating Least Saqures implementation. After building that recommendation system, we will go through the process of adding a new user to the dataset with some new ratings and obtaining new recommendations for that user.\n",
    "\n",
    "### Importing the Data\n",
    "To begin with:\n",
    "* initialize a SparkSession object\n",
    "* import the dataset found at './data/ratings.csv' into a pyspark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHONPATH=/usr/local/Cellar/apache-spark/2.4.3/libexec/python:\r\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "!env | grep PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "spark = (pyspark.sql.SparkSession.builder \n",
    "  .master(\"local[*]\")\n",
    "  .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies.csv  ratings.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ratings.csv: ASCII text, with CRLF line terminators\r\n"
     ]
    }
   ],
   "source": [
    "!file data/ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId,movieId,rating,timestamp\r",
      "\r\n",
      "1,1,4.0,964982703\r",
      "\r\n",
      "1,3,4.0,964981247\r",
      "\r\n",
      "1,6,4.0,964982224\r",
      "\r\n",
      "1,47,5.0,964983815\r",
      "\r\n",
      "1,50,5.0,964982931\r",
      "\r\n",
      "1,70,3.0,964982400\r",
      "\r\n",
      "1,101,5.0,964980868\r",
      "\r\n",
      "1,110,4.0,964982176\r",
      "\r\n",
      "1,151,5.0,964984041\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head data/ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataset into pyspark DataFrame\n",
    "movie_ratings = spark.read.csv('data/ratings.csv',\n",
    "                               inferSchema=True,\n",
    "                               header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data types of each of the values to ensure that they are a type that makes sense given the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    ArrayType,\n",
    "    AtomicType,\n",
    "    BinaryType,\n",
    "    BooleanType,\n",
    "    ByteType,\n",
    "    CloudPickleSerializer,\n",
    "    DataType,\n",
    "    DataTypeSingleton,\n",
    "    DateConverter,\n",
    "    DateType,\n",
    "    DatetimeConverter,\n",
    "    DecimalType,\n",
    "    DoubleType,\n",
    "    FloatType,\n",
    "    FractionalType,\n",
    "    IntegerType,\n",
    "    IntegralType,\n",
    "    JavaClass,\n",
    "    LongType,\n",
    "    MapType,\n",
    "    NullType,\n",
    "    NumericType,\n",
    "    Row,\n",
    "    ShortType,\n",
    "    SparkContext,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    "    TimestampType,\n",
    "    UserDefinedType,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField('userId', IntegerType()),\n",
    "        StructField('movieId', IntegerType()),\n",
    "        StructField('rating', FloatType()),\n",
    "        StructField('timestamp', LongType()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataset into pyspark DataFrame\n",
    "movie_ratings = spark.read.csv('data/ratings.csv',\n",
    "                               inferSchema=False,\n",
    "                               schema=schema,\n",
    "                               header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: int, movieId: int, rating: float, timestamp: bigint]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ratings.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_ratings.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('userId', 'int'),\n",
       " ('movieId', 'int'),\n",
       " ('rating', 'double'),\n",
       " ('timestamp', 'int')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aren't going to need the time stamp, so we can go ahead and remove that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Alternating Least Squares Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this dataset is already preprocessed for us, we can go ahead and fit the Alternating Least Squares model.\n",
    "\n",
    "* Import the ALS module from pyspark.ml.recommendation.\n",
    "* Use the randomSplit method on the pyspark DataFrame to separate the dataset into a training and test set\n",
    "* Fit the Alternating Least Squares Model to the training dataset. Make sure to set the userCol, itemCol, and ratingCol to the appropriate names given this dataset. Then fit the data to the training set and assign it to a variable model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "# split into training and testing sets\n",
    "\n",
    "als = ALS(\n",
    "    rank=10,\n",
    "    maxIter=10,\n",
    "    userCol='userId',\n",
    "    itemCol='movieId',\n",
    "    ratingCol='rating',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "\n",
    "# fit the ALS model to the training set\n",
    "\n",
    "als_model = als.fit(movie_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you've fit the model, and it's time to evaluate it to determine just how well it performed.\n",
    "\n",
    "* import `RegressionEvalutor` from pyspark.ml.evaluation\n",
    "* generate predictions with your model for the test set by using the `transform` method on your ALS model\n",
    "* evaluate your model and print out the RMSE from your test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALSModel.transform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = als_model.transform(movie_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: int, movieId: int, rating: float, timestamp: bigint, prediction: float]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "+------+-------+------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_ratings.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+----------+\n",
      "|userId|movieId|rating|timestamp|prediction|\n",
      "+------+-------+------+---------+----------+\n",
      "|   191|    148|   5.0|829760897|  4.912873|\n",
      "+------+-------+------+---------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_factors = als_model.userFactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, features: array<float>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_factors = als_model.itemFactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "billy_row = user_factors[user_factors['id'] == 10].first()\n",
    "billy_factors = np.array(billy_row['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_row = item_factors[item_factors['id'] == 296].first()\n",
    "m_factors = np.array(m_row['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.48113078,  0.10100795,  0.06847224, -0.07711513,  1.59972095,\n",
       "        1.18931723,  0.74921227,  0.002795  , -0.31532204, -0.30787283])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billy_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.06861246e-01, -9.56375822e-02, -2.69766182e-01, -5.80208361e-01,\n",
       "        1.02675958e-02, -2.74204591e-04,  1.92972398e+00, -2.94304371e-01,\n",
       "       -3.90635788e-01, -1.19364870e+00])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1640822027223257"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billy_factors @ m_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "billy_preds = predictions[predictions['userId'] == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating| timestamp|prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "|    10|    296|   1.0|1455303387| 2.1640823|\n",
      "|    10|    356|   3.5|1455301685| 3.5761378|\n",
      "|    10|    588|   4.0|1455306173| 3.2734149|\n",
      "|    10|    597|   3.5|1455357645| 3.2656565|\n",
      "|    10|    912|   4.0|1455302254| 3.7281077|\n",
      "|    10|   1028|   0.5|1455306152|  2.921604|\n",
      "|    10|   1088|   3.0|1455619275|  3.244572|\n",
      "|    10|   1247|   3.0|1455303518| 2.4162045|\n",
      "|    10|   1307|   3.0|1455357613| 2.9066176|\n",
      "|    10|   1784|   3.5|1455301699|  3.095241|\n",
      "|    10|   1907|   4.0|1455306183| 3.6470838|\n",
      "|    10|   2571|   0.5|1455356378|  3.017029|\n",
      "|    10|   2671|   3.5|1455357517|  3.745073|\n",
      "|    10|   2762|   0.5|1455356388| 2.7671921|\n",
      "|    10|   2858|   1.0|1455356578| 2.6532393|\n",
      "|    10|   2959|   0.5|1455356582|  2.424939|\n",
      "|    10|   3578|   4.0|1455356591| 3.2716172|\n",
      "|    10|   3882|   3.0|1455398344| 3.1183858|\n",
      "|    10|   4246|   3.5|1455302676|  3.357866|\n",
      "|    10|   4306|   4.5|1455356595|  3.569522|\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "billy_preds.sort('movieId').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = als_model.recommendForAllUsers(numItems=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movieId=3086, rating=4.889717102050781),\n",
       " Row(movieId=26614, rating=4.750113487243652),\n",
       " Row(movieId=68073, rating=4.680994033813477),\n",
       " Row(movieId=42730, rating=4.661563396453857),\n",
       " Row(movieId=71579, rating=4.630825519561768),\n",
       " Row(movieId=8869, rating=4.606689929962158),\n",
       " Row(movieId=103372, rating=4.472315311431885),\n",
       " Row(movieId=32892, rating=4.447782039642334),\n",
       " Row(movieId=113275, rating=4.427666664123535),\n",
       " Row(movieId=45503, rating=4.4271650314331055)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs[recs['userId']==10].first()['recommendations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3086,Babes in Toyland (1934),Children|Comedy|Fantasy|Musical\r",
      "\r\n",
      "83086,Burlesque (2010),Drama|Musical|Romance\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!grep 3086 < data/movies.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
